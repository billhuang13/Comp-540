# -*- coding: utf-8 -*-
"""Segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ieotqaaKWZ098VjulWyOxd2YJsgY-Gn8
"""

!pip install -U git+https://github.com/qubvel/segmentation_models.pytorch

pip install torchsummary

from torch.utils.data import Dataset, DataLoader
import cv2
import sys
from glob import glob
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold as kfold
import numpy as np
import torch
import torchvision.transforms as transforms
import os
from tqdm import tqdm
import torch.nn as nn
from torchsummary import summary

import copy
import tempfile
from pathlib import Path
from sklearn import metrics
import random
import segmentation_models_pytorch as smp
from torchsummary import summary
import pandas as pd
seed=42
random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
torch.cuda.manual_seed_all(seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

from google.colab import drive
drive.mount('/content/drive')

root_folder="/content/drive/Shareddrives/Comp 540/Test_shared_Drive"

class MyNpydataset(Dataset):
    def __init__(self, imgs, labels, masks, names, preprocess=None,preprocess_mask=None):
        """

        :param imgs: [N*1*W*D] or [N*W*D]
        :param labels: [N]
        :param names:  [N]
        :param preprocess:
        """
        self.imgs = imgs
        self.labels = labels
        self.masks = masks
        self.names=names
        self.preprocess = preprocess
        self.preprocess_mask=preprocess_mask

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, index):
        img = self.imgs[index]
        mask = self.masks[index]
        label=self.labels[index]

        if self.preprocess is not None:
            img = self.preprocess(img)
        if self.preprocess_mask is not None:
            mask=self.preprocess_mask(mask)
        return img, mask, label

    def getLabel(self, index):
        return self.labels[index]

    def getMask(self, index):
        return self.masks[index]

    def getName(self, index):
        return self.names[index]


def getDataset(positive_npy_file, positive_names_npy_file, positive_masks_npy_file, get_part_index=-1):

    ################
    # read npy file
    ################
    positives=np.load(positive_npy_file, allow_pickle=True)[()]
    positives_names=np.load(positive_names_npy_file, allow_pickle=True)[()]
    positives_masks=np.load(positive_masks_npy_file, allow_pickle=True)[()]

    #negatives=np.load(negative_npy_file, allow_pickle=True)[()]
    #negatives_names=np.load(negative_names_npy_file, allow_pickle=True)[()]
    #negatives_masks=np.load(negative_masks_npy_file, allow_pickle=True)[()]

    # get part of the data for check
    if get_part_index!=-1:
        positives=positives[:get_part_index]
        positives_names=positives_names[:get_part_index]
        positives_masks=positives_masks[:get_part_index]
        #negatives=negatives[:get_part_index]
        #negatives_names=negatives_names[:get_part_index]
        #negatives_masks=negatives_masks[:get_part_index]


    # get all labels and all images
    all_labels = np.ones((positives.shape[0],))

    all_imgs = positives
    all_names = positives_names
    all_masks=positives_masks
    all_indices = [i for i in range(all_imgs.shape[0])]

    ################
    # def norm
    ################
    def norm_transform(img, dataset_mean, dataset_std):
        return (img - dataset_mean)/dataset_std

    dataset_mean = np.mean(all_imgs)
    dataset_std=np.std(all_imgs)

    preprocess = transforms.Compose([
        lambda img: cv2.resize(img, (224,224)),
        #lambda img: cv2.resize(img, (1024,1024)),
        lambda img: img[None, :, :] if len(img.shape) == 2 else img,  # 1*H*W
        lambda img: norm_transform(img, dataset_mean, dataset_std),
        lambda img: torch.from_numpy(img)
    ])

    preprocess_mask=transforms.Compose([
        lambda mask: cv2.resize(mask, (224,224)),
        #lambda mask: cv2.resize(mask, (1024,1024)),
        lambda mask: np.where(mask < 0.5, 0, 1),
        lambda mask: torch.from_numpy(mask)
    ])


    ################
    # split
    ################
    train_val_indices, test_indices, train_val_labels, test_labels = train_test_split(all_indices,
                                                                                        all_labels,
                                                                                        test_size=0.2,
                                                                                        random_state=42,
                                                                                        stratify=all_labels)

    test_dataset = MyNpydataset(all_imgs[test_indices], test_labels, all_masks[test_indices], all_names[test_indices],
                                preprocess, preprocess_mask)


    skf = kfold(n_splits=5, shuffle=True, random_state=42)
    cur_fold_index = 0
    for trainIndex, testIndex in skf.split(train_val_indices, train_val_labels):
        # get train/val imgs
        train_imgs = all_imgs[[train_val_indices[ix] for ix in trainIndex]]
        val_imgs = all_imgs[[train_val_indices[ix] for ix in testIndex]]

        # get train/val labels
        train_labels = all_labels[[train_val_indices[ix] for ix in trainIndex]]
        val_labels = all_labels[[train_val_indices[ix] for ix in testIndex]]

        # get train/val names
        train_names = all_names[[train_val_indices[ix] for ix in trainIndex]]
        val_names = all_names[[train_val_indices[ix] for ix in testIndex]]

        # get train/val masks
        train_masks = all_masks[[train_val_indices[ix] for ix in trainIndex]]
        val_masks = all_masks[[train_val_indices[ix] for ix in testIndex]]

        break

    ########## get dataset
    train_dataset = MyNpydataset(train_imgs, train_labels, train_masks, train_names,
                                 preprocess, preprocess_mask)
    val_dataset = MyNpydataset(val_imgs, val_labels, val_masks, val_names,
                               preprocess, preprocess_mask)

    print("train len:", train_dataset.__len__(), train_dataset.labels.sum()/len(train_dataset.labels))
    print("val len:", val_dataset.__len__(), val_dataset.labels.sum()/len(val_dataset.labels))
    print("test len:", test_dataset.__len__(), test_dataset.labels.sum()/len(test_dataset.labels))
    return train_dataset, val_dataset, test_dataset

positive_npy_file=f"{root_folder}/processed/new_2img_mask_npy/positive_imgs.npy"
positive_names_npy_file=f"{root_folder}/processed/new_2img_mask_npy/positive_imgs_names.npy"
positive_masks_npy_file=f"{root_folder}/processed/new_2img_mask_npy/positive_masks.npy"

train_set, val_set, test_set=getDataset(positive_npy_file, positive_names_npy_file, positive_masks_npy_file, 2669) # use all of it

len(train_set) + len(val_set) + len(test_set)

img, mask, label=train_set[2]
print(label)
plt.imshow(img[0], cmap="gray")
plt.imshow(mask, cmap="gray", alpha=0.5)
plt.show()

print(mask.min(),mask.max(), mask.shape)

print(img.min(),img.max(), img.shape)
print(img.mean(), img.std())

aux_params=dict(
    pooling='avg',             # one of 'avg', 'max'
    dropout=0.2,               # dropout ratio, default is None
    activation='sigmoid',      # activation function, default is None
    classes=2,                 # define number of output labels
)

model = smp.Unet(
    encoder_name="resnet18",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7
    encoder_weights="imagenet",     # use `imagenet` pre-trained weights for encoder initialization
    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)
    classes=1,                      # model output channels (number of classes in your dataset)
    aux_params=aux_params,
)

device=torch.device("cuda")
model=model.to(device)
summary(model, (1,224,224))

#x=torch.rand(10,1,1024,1024).to(device)
x=torch.rand(10,1,224,224).to(device)
model.eval()
with torch.no_grad():
    y=model(x)
    print(y[0].shape)
    print(y[1].shape)

class DiceLoss(nn.Module):
    def __init__(self):
        super(DiceLoss, self).__init__()
        self.smooth=1e-6

    def forward(self, inputs, targets):
        inputs = torch.sigmoid(inputs)
        #flatten label and prediction tensors
        inputs = inputs.view(inputs.shape[0],-1)
        targets = targets.view(targets.shape[0],-1)


        # Calculate intersection and union per batch element
        intersection = (inputs * targets).sum(dim=1)
        total = inputs.sum(dim=1) + targets.sum(dim=1)

        # Compute Dice coefficient for each element in the batch
        dice_score = (2. * intersection + self.smooth) / (total + self.smooth)
        # Average Dice Loss across the batch
        return 1 - dice_score.mean()

def train_model_single(train_loader, val_loader, model,
                       dice_loss_function, optimizer, scheduler, device):
    model = model.to(device)
    dice_loss_function = dice_loss_function.to(device)

    # Training
    model.train()
    loop = tqdm(train_loader, leave=True)
    cumulative_mask_loss = 0

    for batch_idx, (x, mask, _) in enumerate(loop):  # No labels anymore
        xb = x.float().to(device)
        mask = mask.type(torch.FloatTensor).to(device)

        # Forward pass
        predicted_masks, _ = model(xb)

        # Dice Loss
        mask_loss = dice_loss_function(predicted_masks, mask)

        # Backpropagation
        optimizer.zero_grad()
        mask_loss.backward()
        optimizer.step()

        # Track stats
        cumulative_mask_loss += mask_loss.item()
        avg_mask_loss = cumulative_mask_loss / (batch_idx + 1)

        # Update tqdm bar
        loop.set_postfix(mask_loss=avg_mask_loss)

    loop.close()

    ##########
    # Validation
    ##########
    model.eval()
    loop_val = tqdm(val_loader, leave=True)
    cumulative_mask_loss = 0

    with torch.no_grad():
        for batch_idx, (x, mask, _) in enumerate(loop_val):  # No labels anymore
            xb = x.float().to(device)
            mask = mask.type(torch.FloatTensor).to(device)

            # Forward pass
            predicted_masks, _ = model(xb)

            # Dice Loss
            mask_loss = dice_loss_function(predicted_masks, mask)

            # Track stats
            cumulative_mask_loss += mask_loss.item()
            val_avg_mask_loss = cumulative_mask_loss / (batch_idx + 1)

            # Update tqdm bar
            loop_val.set_postfix(val_mask_loss=val_avg_mask_loss)

    loop_val.close()

    return avg_mask_loss, val_avg_mask_loss

def train_model(epochs, train_loader, val_loader, model, dice_loss_function, optimizer, scheduler, device):
    best_val_mask_loss = float('inf')
    train_losses = []
    val_losses = []

    for epoch in range(epochs):
        print(f"Epoch {epoch + 1}/{epochs}")
        avg_mask_loss, val_avg_mask_loss = train_model_single(
            train_loader, val_loader, model, dice_loss_function, optimizer, scheduler, device
        )

        train_losses.append(avg_mask_loss)
        val_losses.append(val_avg_mask_loss)

        # Update scheduler
        if scheduler != -1:
            scheduler.step()

        # Save model if validation loss improves
        if val_avg_mask_loss <= best_val_mask_loss:
            best_val_mask_loss = val_avg_mask_loss
            torch.save(model.state_dict(), "best_so_far.pth")

    # Plot training and validation loss
    plt.figure(figsize=(5, 4))
    plt.plot(range(len(train_losses)), train_losses, label="Train Loss")
    plt.plot(range(len(val_losses)), val_losses, label="Validation Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Dice Loss")
    plt.title("Training and Validation Dice Loss")
    plt.legend()
    plt.show()

    print(f"Best Dice Score : {1 - best_val_mask_loss}")

# Define DiceLoss
dice_loss = DiceLoss()

# Train the model
lr=1e-4
wd=1e-3
scheduler_ld=0.9
B=5

"""
dataloader
"""
train_loader = DataLoader(
    dataset=train_set,
    batch_size=B,
    num_workers=8,
    pin_memory=True,
    shuffle=True,
    drop_last=True,
)

val_loader = DataLoader(
    dataset=val_set,
    batch_size=B,
    num_workers=8,
    pin_memory=True,
    shuffle=True,
    drop_last=False,
)

"""
model
"""
device=torch.device("cuda")
model = smp.Unet(
    encoder_name="resnet18",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7
    encoder_weights="imagenet",     # use `imagenet` pre-trained weights for encoder initialization
    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)
    classes=1,                      # model output channels (number of classes in your dataset)
    aux_params=aux_params,
)

"""
cost function
"""
positive_ratio = train_set.labels.sum() / len(train_set.labels)
class_weights = [positive_ratio, 1 - positive_ratio]
print("class_weights:", class_weights)
class_cost_function = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float)).to(device)
mask_cost_function=DiceLoss().to(device)

"""
optimizer
"""
optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
lambda1 = lambda epoch: scheduler_ld ** epoch
scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)

"""
train
"""
# train_model(10,train_loader, val_loader, model, class_cost_function, mask_cost_function, optimizer, scheduler, device)
# todo, for check
train_model(10,train_loader, val_loader, model, dice_loss, optimizer, scheduler, device)

# load model
device=torch.device("cuda")

aux_params=dict(
    pooling='avg',             # one of 'avg', 'max'
    dropout=0.2,               # dropout ratio, default is None
    activation='sigmoid',      # activation function, default is None
    classes=2,                 # define number of output labels
)

model = smp.Unet(
    encoder_name="resnet18",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7
    encoder_weights="imagenet",     # use `imagenet` pre-trained weights for encoder initialization
    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)
    classes=1,                      # model output channels (number of classes in your dataset)
    aux_params=aux_params,
)

model.load_state_dict(torch.load("best_so_far.pth", map_location=device), strict=True)
model=model.to(device)

import matplotlib.pyplot as plt
import numpy as np

# Move the model to evaluation mode
model = model.to(device)
model.eval()

# Loop through the first 10 images in the dataset
for i in range(10):
    img, mask, label = train_set[i]  # Load the image, mask, and label
    img = img.float().to(device)

    # Predict the mask
    with torch.no_grad():
        pred_masks, _ = model(img[None, :, :, :])  # Add batch dimension

    # Threshold the predicted mask
    pred_masks_threshed = pred_masks[0, 0].cpu().numpy()  # Remove batch and channel dimensions
    pred_masks_threshed = np.where(pred_masks_threshed < 0.9, 0, 1)  # Apply threshold

    # Plot the original image, prediction, and target
    fig, axes = plt.subplots(1, 2, figsize=(4, 4))

    # Show the ground truth mask
    axes[0].imshow(mask, cmap="gray")
    axes[0].set_title("Original")
    axes[0].axis("off")

    # Show the predicted mask
    axes[1].imshow(pred_masks_threshed, cmap="gray")
    axes[1].set_title("Prediction")
    axes[1].axis("off")

    plt.tight_layout()
    plt.show()

def avg_dice_loss(model, test_loader, dice_loss_fn, device):
    model.eval()  # Set the model to evaluation mode
    total_dice_loss = 0.0
    num_samples = 0

    with torch.no_grad():  # No gradients needed during evaluation
        loop = tqdm(test_loader, leave=True)
        for img, mask, _ in loop:  # Assuming test_loader yields (image, mask, label)
            # Move data to the device
            img = img.float().to(device)
            mask = mask.float().to(device)

            # Get predictions
            pred_masks, _ = model(img)

            # Compute Dice loss for the batch
            dice_loss = dice_loss_fn(pred_masks, mask)

            # Update cumulative Dice loss and sample count
            batch_size = img.size(0)
            total_dice_loss += dice_loss.item() * batch_size
            num_samples += batch_size

            # Update tqdm description
            loop.set_postfix(avg_dice_loss=total_dice_loss / num_samples)

    # Calculate and return the average Dice loss
    avg_dice_loss = total_dice_loss / num_samples
    return avg_dice_loss

test_loader = DataLoader(
    dataset=test_set,
    batch_size=B,
    num_workers=8,
    pin_memory=True,
    shuffle=True,
    drop_last=False)

dice_loss_fn = DiceLoss()

avg_dice_loss(model, test_loader, dice_loss_fn, device)

"""# VGG-13"""

aux_params=dict(
    pooling='avg',             # one of 'avg', 'max'
    dropout=0.2,               # dropout ratio, default is None
    activation='sigmoid',      # activation function, default is None
    classes=2,                 # define number of output labels
)


model = smp.Unet(
    encoder_name="vgg13",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7
    encoder_weights="imagenet",     # use `imagenet` pre-trained weights for encoder initialization
    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)
    classes=1,                      # model output channels (number of classes in your dataset)
    aux_params=aux_params,
)

# Define DiceLoss
dice_loss = DiceLoss()

# Train the model
lr=1e-4
wd=1e-3
scheduler_ld=0.9
B=5

"""
dataloader
"""
train_loader = DataLoader(
    dataset=train_set,
    batch_size=B,
    num_workers=8,
    pin_memory=True,
    shuffle=True,
    drop_last=True,
)

val_loader = DataLoader(
    dataset=val_set,
    batch_size=B,
    num_workers=8,
    pin_memory=True,
    shuffle=True,
    drop_last=False,
)

"""
model
"""
device=torch.device("cuda")
model = smp.Unet(
    encoder_name="vgg13",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7
    encoder_weights="imagenet",     # use `imagenet` pre-trained weights for encoder initialization
    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)
    classes=1,                      # model output channels (number of classes in your dataset)
    aux_params=aux_params,
)

"""
cost function
"""
positive_ratio = train_set.labels.sum() / len(train_set.labels)
class_weights = [positive_ratio, 1 - positive_ratio]
print("class_weights:", class_weights)
class_cost_function = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float)).to(device)
mask_cost_function=DiceLoss().to(device)

"""
optimizer
"""
optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
lambda1 = lambda epoch: scheduler_ld ** epoch
scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)

"""
train
"""
# train_model(10,train_loader, val_loader, model, class_cost_function, mask_cost_function, optimizer, scheduler, device)
# todo, for check
train_model(10,train_loader, val_loader, model, dice_loss, optimizer, scheduler, device)

# load model
device=torch.device("cuda")

aux_params=dict(
    pooling='avg',             # one of 'avg', 'max'
    dropout=0.2,               # dropout ratio, default is None
    activation='sigmoid',      # activation function, default is None
    classes=2,                 # define number of output labels
)

model = smp.Unet(
    encoder_name="vgg13",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7
    encoder_weights="imagenet",     # use `imagenet` pre-trained weights for encoder initialization
    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)
    classes=1,                      # model output channels (number of classes in your dataset)
    aux_params=aux_params,
)

model.load_state_dict(torch.load("best_so_far.pth", map_location=device), strict=True)
model=model.to(device)

import matplotlib.pyplot as plt
import numpy as np

# Move the model to evaluation mode
model = model.to(device)
model.eval()

# Loop through the first 10 images in the dataset
for i in range(10):
    img, mask, label = train_set[i]  # Load the image, mask, and label
    img = img.float().to(device)

    # Predict the mask
    with torch.no_grad():
        pred_masks, _ = model(img[None, :, :, :])  # Add batch dimension

    # Threshold the predicted mask
    pred_masks_threshed = pred_masks[0, 0].cpu().numpy()  # Remove batch and channel dimensions
    pred_masks_threshed = np.where(pred_masks_threshed < 0.9, 0, 1)  # Apply threshold

    # Plot the original image, prediction, and target
    fig, axes = plt.subplots(1, 2, figsize=(4, 4))

    # Show the ground truth mask
    axes[0].imshow(mask, cmap="gray")
    axes[0].set_title("Original")
    axes[0].axis("off")

    # Show the predicted mask
    axes[1].imshow(pred_masks_threshed, cmap="gray")
    axes[1].set_title("Prediction")
    axes[1].axis("off")

    plt.tight_layout()
    plt.show()

test_loader = DataLoader(
    dataset=test_set,
    batch_size=B,
    num_workers=8,
    pin_memory=True,
    shuffle=True,
    drop_last=False)

dice_loss_fn = DiceLoss()

avg_dice_loss(model, test_loader, dice_loss_fn, device)